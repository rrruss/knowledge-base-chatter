{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49663e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch as PyTorchEstimator, PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebf46cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3bb291",
   "metadata": {},
   "source": [
    "## Download test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb2891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0d8adc",
   "metadata": {},
   "source": [
    "#### Context Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a9364a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5400d461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91456d18144e4ce6b53aea5e5ab603d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab32d46864de4d099f8d5ea4292c7ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bded6eb6077e4bccbc209093c4cd13db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2312b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2691c9bb9fe34389ad544b1a7d1e058e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/492 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258e2201be9a4a69a761cae06f45212c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_model = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c92e157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = c_tokenizer(\"Hello, is my dog cute ?\", return_tensors='pt')[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df0c1291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    embeddings = c_model(input_ids).pooler_output\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad91ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_tokenizer.save_pretrained('code/dpr-ctx_encoder-single-nq-base-tokenizer')\n",
    "c_model.save_pretrained('code/dpr-ctx_encoder-single-nq-base-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c71f97",
   "metadata": {},
   "source": [
    "#### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2aebd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91ff5b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d654231d2ce74b7c899bd39454ca2d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f509703e9f7443abb600b631069a68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bafbd03ac704d9fb1e9431be1ae41a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59107dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab37dddcc28d4772ab8d119429f56012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/493 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290dd5fd60ac420293c3544681ac7d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_model = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "641ed747",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = q_tokenizer(\"Hello, is my dog cute ?\", return_tensors='pt')[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e54cf5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    embeddings = q_model(input_ids).pooler_output\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a2c0d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_tokenizer.save_pretrained('code/dpr-question_encoder-single-nq-base-tokenizer')\n",
    "q_model.save_pretrained('code/dpr-question_encoder-single-nq-base-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47954174",
   "metadata": {},
   "source": [
    "#### Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ba17f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DPRReader, DPRReaderTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c35a31b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34224b2bf87f45a0aa229bb7c2191423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9daa7a2be3eb4ed68dfb7ef138f5cb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df043391c3884759af4384142472385a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_tokenizer = DPRReaderTokenizer.from_pretrained('facebook/dpr-reader-single-nq-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "325b7f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e75a50f48794ba8aa7db72f1808707f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/484 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1eee3704d84c3b82d637f75d24b837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_model = DPRReader.from_pretrained('facebook/dpr-reader-single-nq-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80d99531",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs = r_tokenizer(\n",
    "        questions=[\"What is love ?\"],\n",
    "        titles=[\"Haddaway\"],\n",
    "        texts=[\"'What Is Love' is a song recorded by the artist Haddaway\"],\n",
    "        return_tensors='pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f832866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = r_model(**encoded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "339271d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "relevance_logits = outputs.relevance_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8bcba73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.5585e-04, 2.2813e-04, 1.1821e-04, 1.0410e-04, 8.9758e-05, 4.9391e-04,\n",
      "         3.3133e-04, 9.3138e-05, 7.6866e-05, 4.9471e-04, 2.4096e-04, 6.1555e-03,\n",
      "         3.0341e-04, 5.4163e-04, 1.1801e-04, 2.0656e-03, 7.0882e-01, 2.0653e-03,\n",
      "         1.3085e-03, 3.0284e-04, 5.9053e-03, 4.0717e-03, 2.6339e-01, 6.1443e-04,\n",
      "         1.8134e-03]]) tensor([[0.0048, 0.0015, 0.0020, 0.0054, 0.0038, 0.1663, 0.0012, 0.0021, 0.0069,\n",
      "         0.1666, 0.0012, 0.0020, 0.0018, 0.0424, 0.0026, 0.0013, 0.0055, 0.1844,\n",
      "         0.0043, 0.0105, 0.0500, 0.1402, 0.0529, 0.0058, 0.1346]]) tensor([-1.2456])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    print(torch.softmax(start_logits, dim=-1), torch.softmax(end_logits, dim=-1), relevance_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abe82417",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_tokenizer.save_pretrained('code/dpr-reader-single-nq-base-tokenizer')\n",
    "r_model.save_pretrained('code/dpr-reader-single-nq-base-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0057587a",
   "metadata": {},
   "source": [
    "#### Generate full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "26e959bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "80f8068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.c_model = DPRContextEncoder.from_pretrained('code/dpr-ctx_encoder-single-nq-base-model')\n",
    "        self.c_tokenizer = DPRContextEncoderTokenizer.from_pretrained('code/dpr-ctx_encoder-single-nq-base-tokenizer')\n",
    "        self.q_model = DPRQuestionEncoder.from_pretrained('code/dpr-question_encoder-single-nq-base-model')\n",
    "        self.q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('code/dpr-question_encoder-single-nq-base-tokenizer')\n",
    "        self.r_model = DPRReader.from_pretrained('code/dpr-reader-single-nq-base-model')\n",
    "        self.r_tokenizer = DPRReaderTokenizer.from_pretrained('code/dpr-reader-single-nq-base-tokenizer')\n",
    "        with open('code/pg1974.txt') as f:\n",
    "            self.text = re.sub(r'\\s+', ' ', f.read())\n",
    "        self.contexts = re.findall(r'.{7,}?[.?!]', self.text)\n",
    "        context_embeddings = []\n",
    "        with torch.no_grad():\n",
    "            for context in self.contexts:\n",
    "                input_ids = c_tokenizer(context, return_tensors='pt')[\"input_ids\"]\n",
    "                output = self.c_model(input_ids)\n",
    "                context_embeddings.append(output.pooler_output)\n",
    "        self.context_embeddings = nn.Parameter(torch.cat(context_embeddings, dim=0))\n",
    "    \n",
    "    def forward(self, question):\n",
    "        q_input_ids = self.q_tokenizer(question, return_tensors='pt')['input_ids']\n",
    "        q_output = self.q_model(q_input_ids)\n",
    "        q_embedding = q_output.pooler_output\n",
    "        similarities = torch.cosine_similarity(q_embedding, self.context_embeddings)\n",
    "        topk_similarities = torch.topk(similarities, k=10, dim=-1)\n",
    "        contexts = [self.contexts[i] for i in topk_similarities.indices]\n",
    "        encoded_inputs = r_tokenizer(\n",
    "            questions=[question for _ in contexts],\n",
    "#             titles=[],\n",
    "            texts=contexts,\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        r_output = self.r_model(**encoded_inputs)\n",
    "        return r_output.start_logits, r_output.end_logits, encoded_inputs['input_ids'], r_output.relevance_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e5036468",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4af56670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ -6.7622,  -8.6719,  -9.3351,  -9.5752,  -9.6634,  -9.3313,  -8.2687,\n",
      "          -8.9506,  -8.5052,  -7.6946,  -9.4911,  -9.0801,  -9.4368,  -6.3643,\n",
      "          -9.2788, -10.2195, -10.3676, -10.4112, -10.0516, -11.0452, -10.0121,\n",
      "          -8.1517,  -8.9436,  -9.3258,  -9.2168,  -9.3015, -11.0162, -11.5700,\n",
      "         -12.1127, -11.9149, -11.5115, -12.0661, -12.2538, -12.3589, -12.3723,\n",
      "         -12.2063, -12.2309, -12.4014, -12.3581, -12.3731, -12.2477, -12.3694,\n",
      "         -12.4034, -12.3199, -12.4176, -12.3798, -10.2013, -12.3394, -12.4206,\n",
      "         -12.4058, -12.3400, -12.1302, -12.0025, -12.1467, -12.0612, -11.4663,\n",
      "         -11.6981, -12.1386, -12.0845, -11.9194, -11.5851, -12.2261, -12.2780,\n",
      "         -12.3107, -12.2934, -12.3199, -12.2477, -12.3278, -12.3605, -12.3724,\n",
      "         -12.3932, -12.2460],\n",
      "        [ -8.1278,  -9.1700,  -9.9306,  -9.9237, -10.6872,  -9.6525,  -8.8582,\n",
      "          -8.4431,  -9.3546, -10.0778,  -9.5079,  -9.4735, -10.5986,  -9.8921,\n",
      "         -10.6934,  -4.7591,  -5.0246,  -9.1500, -10.1506, -11.7996,  -8.6641,\n",
      "          -6.6461,  -8.6234,  -9.7550,  -7.9574,  -8.2077,  -4.4758,  -9.9062,\n",
      "          -9.9590,  -9.7901, -11.0976, -11.8889, -10.4337, -10.9534, -10.9469,\n",
      "          -6.6322,  -9.5484,  -8.7752,  -8.9577,  -7.6897, -12.2950, -12.2668,\n",
      "          -9.8433, -10.3719, -10.4823,  -9.7423,  -9.9424,  -9.6174,  -9.6308,\n",
      "         -11.8268, -11.8369, -12.0097, -12.4955, -12.3995, -12.5020, -12.5701,\n",
      "         -12.5296, -12.5508, -12.4979, -12.4284, -12.5225, -12.4110, -12.3986,\n",
      "         -12.5465, -12.3885, -12.0540, -12.1903, -12.3012, -12.4953, -12.4001,\n",
      "         -12.4329, -12.5256],\n",
      "        [ -8.7683,  -9.8708, -10.3360, -10.2438, -10.8977,  -9.4336, -10.4548,\n",
      "         -10.0494, -10.3615, -10.9683,  -9.3154,  -9.7901,  -9.6039,  -7.7708,\n",
      "         -11.1227,  -6.4313,  -8.3387, -10.1695,  -9.5767, -10.0464,  -9.4515,\n",
      "         -10.1300, -10.8637, -10.1418,  -6.9159, -10.6634, -10.2935,  -9.9393,\n",
      "          -8.8121,  -9.3373, -10.7633, -11.1671, -10.7504,  -9.5999, -10.5866,\n",
      "          -9.3410, -11.3879,  -9.5074,  -9.7869, -10.8826, -12.8568, -10.8725,\n",
      "         -10.8373,  -9.5363, -10.4300, -10.9168,  -5.3575,  -6.5922,  -9.6211,\n",
      "          -9.3955, -11.3444, -11.5908, -12.2510, -12.2464, -12.5643, -12.3677,\n",
      "         -12.5254, -12.6188, -12.5462, -12.5929, -12.5282, -12.5669, -12.6690,\n",
      "         -12.7421, -12.4997, -12.2332, -12.0214, -12.5166, -12.7261, -12.6934,\n",
      "         -12.6251, -12.7313],\n",
      "        [ -9.0062, -10.2699, -10.7253, -10.8868, -11.0369,  -9.5671, -10.0078,\n",
      "         -10.4584, -10.3295, -10.5321, -10.7715,  -4.3123,  -9.2112,  -7.1885,\n",
      "         -11.5546,  -8.9778,  -8.8809, -10.9323, -10.9150, -10.0788,  -9.2880,\n",
      "          -8.3596,  -3.8338, -10.3146,  -4.1844, -11.4731,  -9.9900, -10.7288,\n",
      "          -6.4420,  -7.6556,  -6.8732,  -9.5863,  -9.5487, -12.0085, -12.0334,\n",
      "         -12.2316, -12.2345, -12.3268, -12.3497, -12.5639, -12.5976, -12.5986,\n",
      "         -12.5009, -12.5281, -12.5946, -12.4638, -11.9292, -12.4785, -12.5746,\n",
      "         -12.6335, -12.6541, -12.6244, -12.6244, -12.6018, -12.5820, -12.5943,\n",
      "         -12.5224, -12.5488, -12.4763, -12.3762, -12.4505, -12.1609, -12.1967,\n",
      "         -12.5518, -12.5749, -12.3646, -12.5186, -12.6090, -12.6465, -12.6041,\n",
      "         -12.3946, -12.4673],\n",
      "        [ -7.5481,  -8.5871,  -9.3542,  -7.7077, -10.0583,  -9.8200,  -8.5726,\n",
      "          -7.8394, -10.5144,  -9.5566, -10.1157,  -9.5942,  -5.5790,  -8.8327,\n",
      "          -8.8152,  -8.8026,  -6.8329, -10.3911, -10.0322,  -7.3160,  -9.7358,\n",
      "          -5.7687,  -4.3597,  -8.9367,  -7.7109, -10.0583,  -8.5986,  -7.7660,\n",
      "          -5.6903,  -9.8451,  -5.8382,  -9.7642,  -1.4570, -10.0980,  -9.2706,\n",
      "          -6.6775,  -8.3190, -10.1785,  -8.9308,  -9.7824,  -9.7911, -11.7507,\n",
      "         -11.8114, -12.4627, -12.5555, -12.4060, -12.3191, -12.3685, -12.6054,\n",
      "         -12.5864, -12.3177, -12.3176, -12.5475, -12.6131, -12.6005, -12.5194,\n",
      "         -12.5496, -12.5555, -12.5059, -12.4738, -12.5071, -12.5505, -12.5625,\n",
      "         -12.5983, -12.5024, -12.4248, -11.8879, -12.2392, -12.4068, -11.9021,\n",
      "         -11.6366, -12.2286],\n",
      "        [ -8.4888,  -9.1590,  -9.6310,  -9.8906, -10.1993,  -9.7376,  -9.5082,\n",
      "         -10.1460,  -9.9801,  -9.8154, -10.9771, -10.7141, -10.6243, -10.3441,\n",
      "          -8.1372,  -7.0267, -12.2284, -10.5343,  -6.2518,  -9.4496, -10.3993,\n",
      "         -10.5959, -10.6809, -10.2335,  -9.1266,  -5.1371, -11.0397, -10.0944,\n",
      "         -10.5645,  -9.3105, -11.0743, -11.0317,  -7.0706,  -8.6133,  -9.7466,\n",
      "         -10.2618,  -7.0499,  -9.7576,  -9.7065, -10.7557,  -9.8631,  -9.5653,\n",
      "          -8.3307, -11.9989,  -9.8512,  -8.3434, -11.2552, -10.3372, -10.1924,\n",
      "          -8.9700,  -6.6587, -11.4034, -11.2739, -11.2714, -11.3041, -11.0064,\n",
      "         -11.0844, -10.4815, -11.0647,  -9.3926, -11.4228, -11.2189, -10.8003,\n",
      "          -9.4473, -11.0983, -10.7364, -10.9843, -10.3107, -10.6438, -10.9454,\n",
      "          -9.5792,  -9.7031],\n",
      "        [ -9.9522, -11.2657, -11.2949, -11.4136, -12.0152,  -9.4963, -10.4253,\n",
      "         -10.5423,  -9.7949, -10.7327,  -9.9621, -10.7510,  -1.7833,  -8.3046,\n",
      "          -9.5124, -10.3938, -11.7036,  -6.2054,  -8.6610,  -9.2234,  -9.6427,\n",
      "          -8.3732,  -9.5205,  -8.0289,  -3.0842, -10.8405,  -9.4876, -11.9574,\n",
      "         -12.3850, -12.6209, -12.8317, -12.4597, -12.4734, -12.7537, -12.8150,\n",
      "         -12.7364, -12.7527, -12.7945, -12.7814, -12.7635, -12.8510, -12.3552,\n",
      "         -12.5815, -12.8432, -12.6966, -12.7886, -12.1613, -12.8294, -12.8826,\n",
      "         -12.7768, -12.9437, -12.9120, -12.8291, -12.7064, -12.7947, -12.9550,\n",
      "         -12.1116, -12.3674, -12.7278, -12.6675, -12.2942, -12.2721, -12.4729,\n",
      "         -12.7198, -12.7438, -12.7422, -12.6966, -12.8190, -12.8476, -12.5103,\n",
      "         -12.0101, -12.3871],\n",
      "        [ -6.3879,  -8.0915,  -8.7212,  -7.5023,  -9.2464,  -9.1666,  -8.4970,\n",
      "          -9.8679, -10.8454,  -9.7030,  -9.6736,  -9.7149, -10.4390, -10.1600,\n",
      "          -5.5440, -10.2634, -10.1687, -10.2149, -11.3217, -10.1017,  -8.9934,\n",
      "          -7.4726,  -6.8194, -11.8433, -11.6360,  -9.1585, -10.5689, -11.0523,\n",
      "         -11.8944, -11.6758, -11.1961, -11.6726, -12.0333, -12.1930, -12.0991,\n",
      "         -11.8903, -11.9310, -11.9282, -12.0450, -12.1273, -11.8794, -12.1064,\n",
      "         -12.2271, -12.2878, -12.3543, -12.1700, -12.2326, -12.3541, -12.3597,\n",
      "         -12.3408, -12.1994, -11.8295, -11.7221, -11.7617, -11.7566, -11.1661,\n",
      "         -11.1245, -11.7452, -11.4967, -11.4216, -11.3511, -11.6142, -11.9739,\n",
      "         -12.1472, -11.8775, -11.5775, -11.6623, -11.9214, -12.1468, -12.0681,\n",
      "         -11.8667, -11.9890],\n",
      "        [ -6.3532,  -8.5440,  -9.1034,  -7.8247,  -9.4766,  -8.9294,  -8.5704,\n",
      "          -8.9171,  -9.6731,  -9.2585,  -2.6894,  -3.2721, -10.0839,  -7.5810,\n",
      "          -9.0617,  -9.7567, -10.4780, -10.7346,  -8.9345, -10.5822, -11.3658,\n",
      "          -8.9008, -10.5443, -11.0379, -11.9671, -11.8252, -11.9085, -12.2493,\n",
      "         -12.4013, -12.2757, -12.2043, -12.0707, -12.2704, -12.3612, -12.1472,\n",
      "         -12.2793, -12.1734, -12.3662, -12.4408, -12.3933, -12.4324, -12.4958,\n",
      "         -12.5125, -12.5212, -12.4710, -12.2595, -12.3444, -12.2760, -12.4018,\n",
      "         -12.3888, -12.0590, -11.2393, -11.8911, -12.1547, -12.2472, -12.1012,\n",
      "         -11.8872, -12.0651, -11.7319, -11.5930, -11.3614, -11.3491, -11.9341,\n",
      "         -12.2935, -11.8989, -12.0417, -11.5725, -12.0059, -12.2395, -12.2522,\n",
      "         -12.3332, -12.3883],\n",
      "        [ -6.2934,  -8.6215,  -9.2892,  -6.8453,  -9.3369,  -9.1012,  -7.7517,\n",
      "          -8.9052, -10.2698, -10.1062,  -8.9628, -10.9080,  -7.2604,  -6.9511,\n",
      "          -9.3609, -10.0707,  -8.9582,  -9.7292,  -9.2077,  -9.4609, -10.2226,\n",
      "         -10.3210, -10.3210,  -8.6462, -10.5505,  -9.1941,  -8.5927,  -9.1503,\n",
      "          -8.3489,  -8.0110,  -7.8173, -11.1325,  -9.6023,  -9.3846, -11.6222,\n",
      "         -10.3388,  -8.1687,  -7.0734,  -9.9526,  -5.8302,  -8.9295,  -9.0273,\n",
      "         -10.7789, -11.8318, -12.3482, -12.5586, -12.2348, -11.9575, -12.4324,\n",
      "         -12.6237, -12.6096, -12.5499, -12.6230, -12.5836, -12.6668, -12.6522,\n",
      "         -12.6149, -12.6463, -12.5961, -12.5442, -12.5616, -12.6100, -12.5674,\n",
      "         -12.7485, -12.5938, -12.5949, -12.0136, -12.2065, -12.6326, -12.5779,\n",
      "         -12.6583, -12.5417]]), tensor([[ -5.6091,  -9.0370,  -9.2501,  -8.1926,  -9.3600,  -6.1899,  -6.7541,\n",
      "          -8.8797,  -8.7524, -10.1802,  -9.6386,  -7.0325,  -9.0412,  -7.0442,\n",
      "          -8.1270,  -8.8632, -10.8053,  -9.1609, -10.4440,  -8.5279,  -6.5569,\n",
      "          -7.2904,  -8.3437,  -8.2540,  -5.8285,  -6.1454, -11.3247, -12.0120,\n",
      "         -12.3348, -12.2760, -12.0950, -12.3284, -12.2850, -12.2392, -12.1106,\n",
      "         -12.2709, -12.2632, -12.1354, -12.1520, -12.1623, -12.2516, -12.2306,\n",
      "         -12.1830, -12.2705, -12.1456, -12.1684, -11.1005, -12.1579, -12.1541,\n",
      "         -12.1190, -12.1405, -12.2503, -12.2935, -12.2134, -12.1562, -12.0745,\n",
      "         -12.3639, -12.3475, -12.1084, -12.1695, -12.1941, -12.0715, -12.1522,\n",
      "         -12.1017, -12.0912, -12.1072, -12.1504, -12.1594, -12.2001, -12.1788,\n",
      "         -12.1421, -11.8093],\n",
      "        [ -7.0186,  -9.1537,  -9.7615,  -8.7764,  -9.8168,  -6.7765, -10.5685,\n",
      "          -6.4311,  -8.4701,  -9.6786, -10.0984,  -7.3944, -10.0679,  -9.9625,\n",
      "          -9.2152,  -6.4016,  -3.5167,  -7.7491,  -9.9005,  -7.5240,  -9.3912,\n",
      "          -4.0342,  -9.6587, -10.8006,  -9.4649, -10.3969,  -2.7093,  -6.8525,\n",
      "         -10.1676,  -9.2742, -10.2448,  -8.5157, -10.9465,  -9.1251,  -9.9131,\n",
      "          -6.8012,  -9.3220,  -9.1511,  -9.8185, -13.0700,  -9.4277,  -8.7261,\n",
      "          -9.5954,  -9.5193, -11.1744, -10.9614,  -8.6373,  -6.4902,  -6.7437,\n",
      "         -12.0162, -12.0098, -12.1364, -11.9684, -12.0372, -12.0237, -11.9597,\n",
      "         -12.0146, -11.9716, -11.9911, -12.0608, -12.0048, -12.0775, -12.0643,\n",
      "         -11.9213, -12.0176, -12.1608, -12.0572, -12.0720, -11.9938, -12.0354,\n",
      "         -12.0582, -11.9698],\n",
      "        [ -8.0656,  -9.7350,  -9.8411,  -9.2143, -10.2752,  -6.2389, -10.0850,\n",
      "          -8.2923,  -9.5795, -10.9139,  -9.6821,  -9.5145,  -8.4475,  -5.2118,\n",
      "         -11.2761, -10.6134,  -6.8777, -10.4557,  -9.3275, -11.2443, -10.6936,\n",
      "         -10.0507,  -8.6072, -10.2836,  -8.1525, -10.6250,  -8.5808,  -6.5850,\n",
      "          -9.0940,  -6.0333, -10.0411,  -9.8731, -10.3455, -10.9239,  -8.8978,\n",
      "          -7.0878,  -9.7783, -11.3629, -12.3823, -10.4768,  -8.0576, -10.2505,\n",
      "         -10.5838, -11.3448,  -9.9381, -11.4349,  -8.4745,  -3.9845,  -5.9353,\n",
      "          -6.1703, -11.5906, -11.7958, -12.1290, -12.0561, -11.9977, -12.1689,\n",
      "         -12.1323, -12.0402, -12.0191, -11.9761, -12.0895, -12.0555, -11.9066,\n",
      "         -11.8767, -12.0191, -12.2136, -12.2271, -11.9769, -11.9276, -11.9257,\n",
      "         -12.0129, -11.9316],\n",
      "        [ -8.1325, -10.0711, -10.3683, -10.0320, -10.3533,  -5.9823, -10.8207,\n",
      "          -9.7872,  -9.4715, -10.7441, -10.9878,  -3.6221, -10.6170,  -5.8348,\n",
      "         -10.1646, -10.3200,  -7.7968,  -9.7266,  -9.3210, -11.3186,  -8.4255,\n",
      "         -10.4466,  -2.1890,  -9.4672,  -3.5793, -10.7255,  -9.3403,  -9.4110,\n",
      "         -10.7589,  -8.1921,  -4.4892,  -5.7429,  -5.9494, -12.0843, -12.1423,\n",
      "         -12.2174, -12.1674, -12.1695, -12.1634, -12.0412, -12.0048, -12.0120,\n",
      "         -12.0950, -12.0816, -12.0333, -12.1562, -12.1560, -12.1169, -12.0501,\n",
      "         -11.9904, -11.9536, -12.0040, -11.9987, -12.0205, -12.0785, -12.0502,\n",
      "         -12.1038, -12.0985, -12.1259, -12.1651, -12.1243, -12.1725, -12.2288,\n",
      "         -12.0533, -12.0089, -11.9969, -12.0377, -11.9931, -11.9247, -12.0138,\n",
      "         -12.1710, -12.1165],\n",
      "        [ -6.9391,  -8.8156,  -9.4568,  -6.2704,  -9.4736,  -6.0441,  -8.5685,\n",
      "          -7.2565,  -9.9825,  -9.0716,  -9.8297, -10.3614,  -6.4478,  -8.3702,\n",
      "         -10.5391,  -9.6985,  -6.5231,  -9.2944, -10.5359,  -6.9783,  -9.4938,\n",
      "         -11.0397,  -2.3066,  -9.5998, -10.6803,  -8.8440,  -9.6353, -10.9724,\n",
      "          -5.8073,  -9.8577,  -7.4983, -10.6327,  -0.4495,  -8.7903, -10.6459,\n",
      "         -11.8059, -11.4752,  -9.3754,  -8.8974,  -5.7666,  -5.9893, -11.5768,\n",
      "         -11.4521, -11.8057, -11.7140, -11.7706, -11.8659, -11.8052, -11.7532,\n",
      "         -11.8089, -11.8175, -11.9177, -11.8314, -11.7116, -11.8479, -11.8605,\n",
      "         -11.8135, -11.8611, -11.6564, -11.6403, -11.6941, -11.7806, -11.6899,\n",
      "         -11.6177, -11.7380, -11.8275, -11.6305, -11.7433, -11.7604, -11.5180,\n",
      "         -11.3458, -11.8633],\n",
      "        [ -7.6615,  -9.1778,  -9.6632,  -9.0195,  -9.7254,  -7.3754, -10.4247,\n",
      "          -9.5473, -10.0508,  -8.7789, -10.0314, -10.6450,  -9.7524, -10.8947,\n",
      "         -12.0686, -12.2248,  -7.5299,  -9.7950,  -5.6752,  -8.7495, -10.5238,\n",
      "          -9.7375, -10.6360, -10.6833, -11.3865,  -4.2308,  -9.0080, -11.0972,\n",
      "         -11.0709, -12.8315, -10.7604, -11.0948,  -8.0196,  -7.8618, -11.3433,\n",
      "         -11.3327,  -4.9729,  -7.3347, -11.1422, -10.0468, -10.2053, -11.6501,\n",
      "         -11.3442,  -8.6923, -11.6200,  -6.3455,  -9.5412, -10.1547, -10.4024,\n",
      "          -8.9011,  -7.2844,  -9.0413,  -6.3981,  -9.6707, -10.2679,  -9.5943,\n",
      "         -10.5011,  -9.9657, -10.4442, -10.0987,  -8.9284,  -8.1334, -10.7970,\n",
      "         -10.9377,  -7.2071, -10.4750, -10.8046, -11.2113, -11.5682, -10.0086,\n",
      "          -7.0123,  -7.3260],\n",
      "        [ -8.5904, -10.6522, -10.9372,  -9.9309, -10.6492,  -6.1991, -12.0067,\n",
      "         -11.1031, -10.8038, -11.5689, -10.5563,  -8.4276,  -0.6262,  -8.0487,\n",
      "          -9.9136, -11.4304, -11.8161,  -4.4184,  -8.7996,  -8.1788, -11.2976,\n",
      "         -10.4659,  -8.7758, -11.6765,  -1.8086,  -7.1078,  -6.1853, -12.0642,\n",
      "         -12.0453, -11.9311, -11.6986, -12.0386, -12.0662, -11.8277, -11.7308,\n",
      "         -11.8430, -11.7773, -11.7530, -11.7753, -11.7718, -11.6662, -12.0852,\n",
      "         -11.9412, -11.6907, -11.8386, -11.7517, -11.6651, -11.6664, -11.6024,\n",
      "         -11.7085, -11.4936, -11.5523, -11.6490, -11.7875, -11.7105, -11.4284,\n",
      "         -12.2097, -12.1464, -11.7738, -11.8286, -12.1553, -12.1591, -12.0771,\n",
      "         -11.8373, -11.7459, -11.7788, -11.7873, -11.6653, -11.6313, -11.9684,\n",
      "         -12.0027, -12.0528],\n",
      "        [ -5.4270,  -8.1253,  -8.8025,  -6.1308,  -8.4991,  -6.5441,  -8.5837,\n",
      "         -10.9422,  -8.6369,  -9.9594,  -9.5181, -10.4845, -10.6750, -10.4905,\n",
      "          -5.4728,  -9.3992,  -9.8191,  -8.6017,  -7.3610,  -8.5825,  -9.6746,\n",
      "         -10.3661, -10.5928,  -5.6523, -10.5714,  -6.5234, -10.8929, -11.2966,\n",
      "         -11.6980, -11.4898, -11.3665, -11.6726, -11.7189, -11.6161, -11.4728,\n",
      "         -11.5284, -11.7060, -11.6494, -11.5554, -11.5961, -11.5982, -11.8391,\n",
      "         -11.7679, -11.7702, -11.7513, -11.6990, -11.5057, -11.8056, -11.6887,\n",
      "         -11.6133, -11.6618, -11.6471, -11.7610, -11.6650, -11.4891, -11.4411,\n",
      "         -11.3197, -11.5183, -11.0901, -11.1322, -11.3480, -11.5088, -11.7004,\n",
      "         -11.4823, -11.3305, -11.4521, -11.7616, -11.6277, -11.5738, -11.5597,\n",
      "         -11.5552, -11.6769],\n",
      "        [ -5.2028,  -8.4228,  -8.7265,  -6.5282,  -8.5602,  -5.4254,  -8.5906,\n",
      "          -5.3481,  -8.1287,  -9.3137,  -4.7886,  -1.2843,  -8.4571,  -9.2688,\n",
      "          -8.5375, -10.1779,  -8.2402, -10.3661, -10.0312,  -8.5954, -10.3822,\n",
      "          -5.3750, -10.9359, -11.2302, -11.8207, -11.5721, -11.7082, -11.8482,\n",
      "         -11.6566, -11.6020, -11.6840, -11.5168, -11.7715, -11.5757, -11.3097,\n",
      "         -11.7582, -11.6263, -11.6631, -11.6319, -11.4336, -11.6953, -11.6068,\n",
      "         -11.4983, -11.6408, -11.4677, -11.3864, -11.4162, -11.5536, -11.7272,\n",
      "         -11.5866, -11.4684, -11.6917, -11.7699, -11.4102, -11.6596, -11.4308,\n",
      "         -11.3751, -11.5432, -11.0461, -11.0873, -11.2524, -11.4455, -11.7820,\n",
      "         -11.5369, -11.1520, -11.5566, -11.1411, -11.3924, -11.5497, -11.3984,\n",
      "         -11.5883, -11.5183],\n",
      "        [ -5.4852,  -8.5191,  -8.9863,  -5.1377,  -8.9576,  -4.9948, -10.2172,\n",
      "          -7.7057,  -8.8428, -11.1308,  -6.9503, -10.4883,  -9.7095,  -7.4180,\n",
      "          -8.8336, -10.8563, -11.5091,  -8.3963,  -5.0083,  -9.0764,  -9.9047,\n",
      "         -10.1475, -10.1493,  -9.3837,  -9.0252,  -4.9124,  -9.1706,  -8.8809,\n",
      "         -10.1570,  -7.6777,  -5.7453,  -9.7730,  -9.8607, -10.7843,  -9.4828,\n",
      "         -10.7225, -10.4258,  -7.4685,  -9.5900,  -4.7159,  -4.4482,  -4.8770,\n",
      "         -10.9269, -11.9303, -12.1328, -11.9130, -11.8295, -12.1620, -12.0876,\n",
      "         -11.8872, -11.8989, -11.9717, -11.8997, -11.9486, -11.8403, -11.8414,\n",
      "         -11.8696, -11.8967, -11.8569, -11.9380, -11.9383, -11.8770, -11.9582,\n",
      "         -11.7740, -11.8835, -11.8756, -12.1270, -12.0560, -11.8400, -11.8496,\n",
      "         -11.6814, -11.9866]]), tensor([[  101,  2054,  2003,  4038,  1029,   102,  4038,  2018,  2525,  2579,\n",
      "         15298,  4338,  2043,  5021,  9736,  1010,  8200,  2135,  2061,  2170,\n",
      "          1010,  2024,  2657,  1997,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2054,  2003,  4038,  1029,   102,  1999,  4038,  2023,  2003,\n",
      "          2525,  6835,  1024,  2005,  2182,  1996,  4802,  2034,  9570,  2015,\n",
      "          1996,  5436,  2006,  1996,  3210,  1997,  9723,  1010,  1998,  2059,\n",
      "         19274,  2015,  8281,  3415,  1025,  1011,  1011,  4406,  1996, 10437,\n",
      "          7828,  2545,  2040,  4339,  2055,  3327,  3633,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2054,  2003,  4038,  1029,   102,  1058,  4038,  2003,  1010,\n",
      "          2004,  2057,  2031,  2056,  1010,  2019, 20017,  1997,  3494,  1997,\n",
      "          1037,  2896,  2828,  1010,  2025,  1010,  2174,  1010,  1999,  1996,\n",
      "          2440,  3168,  1997,  1996,  2773,  2919,  1010,  1996, 11320, 14808,\n",
      "         13288,  2108,  6414,  1037, 12572,  1997,  1996,  9200,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2054,  2003,  4038,  1029,   102,  1996,  2168,  7835,  6017,\n",
      "          2125, 10576,  2013,  4038,  1025,  2005,  4038,  8704,  2012,  5052,\n",
      "          2273,  2004,  4788,  1010, 10576,  2004,  2488,  2084,  1999,  5025,\n",
      "          2166,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2054,  2003,  4038,  1029,   102,  2027, 11234,  1010,  2174,\n",
      "          1010,  2013,  2028,  1024,  2178,  1999,  2093, 17475,  1010,  1011,\n",
      "          1011,  1996,  5396,  1010,  1996,  5200,  1010,  1996,  5450,  2030,\n",
      "          5549,  1997, 20017,  1010,  2108,  1999,  2169,  2553,  5664,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2054,  2003,  4038,  1029,   102,  1996,  4366,  2000,  4038,\n",
      "          2003,  2404,  2830,  2011,  1996, 13164, 23543,  1010,  1011,  1011,\n",
      "          2025,  2069,  2011,  2216,  1997,  5483,  5372,  1010,  2040,  2035,\n",
      "         24746,  2008,  2009,  7940,  2104,  2037,  7072,  1010,  2021,  2036,\n",
      "          2011,  1996, 13164, 23543,  1997, 12071,  1010,  2005,  1996,  4802,\n",
      "          8680,  8167,  7606,  1010,  2040,  2003,  2172,  3041,  2084,  9610,\n",
      "         10698,  6155,  1998, 23848,  5267,  1010,  6272,  2000,  2008,  2406,\n",
      "          1012,   102],\n",
      "        [  101,  2054,  2003,  4038,  1029,   102,  2022,  2008,  2004,  2009,\n",
      "          2089,  1010, 10576,  1011,  1011,  2004,  2036,  4038,  1011,  1011,\n",
      "          2001,  2012,  2034,  8210, 24584,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2054,  2003,  4038,  1029,   102,  1037,  4487,  7542,  2008,\n",
      "          2003,  2081,  2039,  1997,  4326,  1006,  2030,  4678,  1007,  3408,\n",
      "          2003,  1037, 15723,  7446,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2054,  2003,  4038,  1029,   102,  2005,  1996, 11305,  1997,\n",
      "          1037, 21834,  2003,  2000,  4671,  2995,  8866,  2104,  5263, 14930,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2054,  2003,  4038,  1029,   102,  1996, 21177,  2038,  1010,\n",
      "          5262,  1010,  2019,  6832,  8432,  1997,  2049,  2219,  1010,  2021,\n",
      "          1010,  1997,  2035,  1996,  3033,  1010,  2009,  2003,  1996,  2560,\n",
      "          6018,  1010,  1998,  4198,  2560,  2007,  1996,  2396,  1997,  4623,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), tensor([-10.5345,  -9.8006,  -9.5441,  -7.1848,  -8.9696,  -9.5885,  -5.7210,\n",
      "        -11.6896, -10.9952, -11.3929]))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(model('What is comedy?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a64fa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12) tensor(12)\n",
      "tragedy\n",
      "[CLS] what is comedy? [SEP] be that as it may, tragedy - - as also comedy - - was at first mere improvisation. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "\n",
      "tensor(22) tensor(22)\n",
      "worse\n",
      "[CLS] what is comedy? [SEP] the same distinction marks off tragedy from comedy ; for comedy aims at representing men as worse, tragedy as better than in actual life. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "\n",
      "tensor(32) tensor(32)\n",
      "imitation\n",
      "[CLS] what is comedy? [SEP] they differ, however, from one : another in three respects, - - the medium, the objects, the manner or mode of imitation, being in each case distinct. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "\n",
      "tensor(46) tensor(47)\n",
      "the ugly\n",
      "[CLS] what is comedy? [SEP] v comedy is, as we have said, an imitation of characters of a lower type, not, however, in the full sense of the word bad, the ludicrous being merely a subdivision of the ugly. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "\n",
      "tensor(25) tensor(25)\n",
      "greece\n",
      "[CLS] what is comedy? [SEP] the claim to comedy is put forward by the megarians, - - not only by those of greece proper, who allege that it originated under their democracy, but also by the megarians of sicily, for the poet epicharmus, who is much earlier than chionides and magnes, belonged to that country. [SEP]\n",
      "\n",
      "total time: 0.6075410842895508\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "start_time = time()\n",
    "with torch.no_grad():\n",
    "    start_logits, end_logits, input_ids, relevance_logits = model('What is comedy?')\n",
    "topk_relevant = torch.topk(relevance_logits, k=relevance_logits.shape[0] // 2, dim=-1)\n",
    "starts = torch.argmax(start_logits, dim=-1)\n",
    "ends = torch.argmax(end_logits, dim=-1)\n",
    "for index in topk_relevant.indices:\n",
    "    question_context = input_ids[index]\n",
    "    start = starts[index]\n",
    "    end = ends[index]\n",
    "    print(start, end)\n",
    "    print(r_tokenizer.decode(question_context[start:end + 1]))\n",
    "    print(r_tokenizer.decode(question_context))\n",
    "    print()\n",
    "print('total time:', time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0fa2cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "181567e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "with tarfile.open('model.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('model.pth', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2dc05b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = session.upload_data(path='model.tar.gz', bucket='kbchatter', key_prefix='haystack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "92b7fe1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://kbchatter/haystack/model.tar.gz'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154d6fa8",
   "metadata": {},
   "source": [
    "## Now to deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "34b8698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model = PyTorchModel(model_data=artifact,\n",
    "                             role=role,\n",
    "                             framework_version='1.6.0',\n",
    "                             py_version='py3',\n",
    "                             entry_point='code/predict.py',\n",
    "                             source_dir='code',\n",
    "                             dependencies=[\n",
    "                                 'code/pg1974.txt',\n",
    "                                 'code/dpr-ctx_encoder-single-nq-base-model',\n",
    "                                 'code/dpr-ctx_encoder-single-nq-base-tokenizer',\n",
    "                                 'code/dpr-question_encoder-single-nq-base-model',\n",
    "                                 'code/dpr-question_encoder-single-nq-base-tokenizer',\n",
    "                                 'code/dpr-reader-single-nq-base-model',\n",
    "                                 'code/dpr-reader-single-nq-base-tokenizer'\n",
    "                             ],\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ec48a8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = pytorch_model.deploy(instance_type='ml.c4.xlarge', initial_instance_count=1, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8b0dd156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'pytorch-inference-2021-07-03-22-33-13-305'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint  # for lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9305b4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.serializer = sagemaker.serializers.JSONSerializer()\n",
    "predictor.deserializer = sagemaker.deserializers.JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eb0b7071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f2f30a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tragedy', 'worse', 'imitation', 'the ugly', 'greece']\n",
      "0.992013692855835\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "print(predictor.predict({'question': 'What is comedy?'}))  # need to convert output/input to json for lambda\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.update_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f11dd69",
   "metadata": {},
   "source": [
    "## Inspect the predictor and pytorch_model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e424da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1736f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = inspect.getsource(predictor.__class__)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ad7dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in inspect.getmro(predictor.__class__):\n",
    "    lines = inspect.getsource(cls)\n",
    "    print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f854260",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in inspect.getmro(pytorch_model.__class__):\n",
    "    lines = inspect.getsource(cls)\n",
    "    print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6d94f2",
   "metadata": {},
   "source": [
    "## Remove model and endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fdec4e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a0279950",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9756bcec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
